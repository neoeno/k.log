Today — make the reproducible program.

We're going to use JS because this is pretty cool to be able to use in the 
browser: https://tesseract.projectnaptha.com.

- [x] Write a JS function to extract frames from a video
- [x] Write a JS function to use Tesseract to extract text
- [x] Produce a type like Frame[] where Frame ~ { text: "..." }
- [-] Test it on a bunch of videos

Good progress today. Libraries made it a bit slow.

I've elected to use ffmpeg to upscale images, convert them to grey, and fiddle
with the contrast to improve recognition. It's working pretty well now —
capturing a lot more of the text. A lot faster too.

Should be soon ready to move on and create the interface.
